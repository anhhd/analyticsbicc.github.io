--- 
title: "Logistic Regression"
author: "Ho Duc Ninh"
output:
  html_document:
    code_folding: hide
    fig_caption: yes
    highlight: haddock
    number_sections: yes
    theme: readable
    toc_float: yes
    toc: yes
---

```{r setup, include=FALSE}
setwd("D:/GitHub/analyticsbicc.github.io/Tutorial")
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
library(ggplot2)
library(dplyr)
library(ROCR)
```

# Logistic Regression

## Introduction
 
* Logistic regression or logit regression is a regression model where the dependent variable (DV) is categorical. Binary logistic regression is a type of regression analysis where the dependent variable is a dummy variable (coded 0, 1).

* Logistic regression is used when analyzing whether some event occurred or not, such as voting, participation in a public program, business success or failure, mortality, a hurricane and etc.

## Logistic model

* Same spirit as linear regression

* Desired interpretation: probability to belong to a specific class for the specified inputs. The target value belongs to [0;1].

* Logistic function: 
        $$Logit(p) = Ln(odds) = ln(\frac{p}{1-p}) = \alpha + \sum_{i=1}^n \beta_iX_i$$
    Or:
                          $$f(t) = \frac{1}{( 1+ e^{-t})}$$

* Fitting : Find the estimates that max the likehood of obtaining the training sample. 

# An illustration for logistic regression 

## Objective

Analyse the probability of default using the the expalining variables

## The dataset

The dataset has 4 variables, which are: 
   
* Default: Whether the customer has  actually defaulted or not(binary variable)
* Student: Whether he/she is a student (binary variable)
* Balance: Monthly credit card balance 
* Income: Annual income

## Data exploration   

 Let's see the summary of the dataset 

```{r}
data <- Default
data %>% str
data %>% summary()

data %>% 
  group_by(default) %>% 
  summarise(mean_bal = mean(balance),
            quantile_50_bal = quantile(balance, 0.5),
            mean_inc = mean(income),
            quantile_50_inc=quantile(income,0.5))
```



 The first glance:
 
* There is a notable difference in the mean of balance account of those who defaulted and those who did not.
 
Let's also see the plot of annual incomes and monthly credit card balances of individuals

The individuals who defaulted on their credit card payments are shown in blue, those who did not are shown in red.

```{r}
ggplot(Default, aes(balance, income)) + 
 geom_jitter(aes(color=default)) +
 theme_bw() 
```
 
 From the scatter plot, we can easily see that those have large balance are highly likely to be defaulted. Regarding to income aspect, the difference between groups is not clear.
 
 We will examine the differences in terms of balance and income of the two groups of individuals. 

 With respect to monthly credit card balance: 
```{r}
ggplot(Default, aes(default,balance)) + 
  geom_boxplot(aes(fill = default)) +
  ggtitle("Boxplots of balance as a function of default status") +
  theme_bw() 
```
 
 The plot shows that, there is a significant difference in the monthly balance of those who defaulted and did not default
 
```{r}
ggplot(Default, aes(default,income)) + 
  geom_boxplot(aes(fill = default)) +
  ggtitle("Boxplots of income as a function of default status") +
  theme_bw() 

aov(income ~ default , data = data) %>% TukeyHSD
```

 There is a slight difference between income of those people who defaulted and did not default.

## Logistic model

### Get the train and test set

 We will build model on train test and test the fitted model on test set. 
 
```{r}
bound <- floor((nrow(data)/4)*3)         # define % of training and test set
df <- data[sample(nrow(data)), ]         # sample rows 
train <- data[1:bound, ]              # get training set
test <- data[(bound+1):nrow(df), ]    # get test set
```
  We set the train and test set which account for 75 and 25 percent of total sample respectively.  

### Logistic regression on training set 

 Using logistic regression to predict default = Yes using balance, income and student status. 

```{r}
lr.fit <- glm(default ~ balance +
                        income +
                        student,
            data = train,
            family = binomial())
summary(lr.fit)

```

Interpretation of estimated coefficient:

* The variables: balance and student status are highly associated with the probability of default

* The coefficient for dummy variable (student) is negative, indicating that students are less likely to default than non-student (holding other variables constant)

* We see the coefficient estimate for balance (0.0057) indicates that an increase in balance is associated with an increase in the probability of default

* The z-statistic plays the same role as the t-statistic in the linear regression output

* Null Deviance and Residual Deviance should be small. Model is "good" if Deviance is approx Chi^2 with (df_sat - df_model) degrees of freedom.

### Assessing the predictive ability of the model 

In the steps above, In the steps above, we briefly evaluated the fitting of the model, now we would like to see how the model is doing when predicting y on a new set of data. Our decision boundary will be 0.5. If $$P(y =1|X) > 0.5$$ then y=1 otherwise y=0. 
```{r}

predTst <- predict(lr.fit, test, type = "response")

glm.pred <- rep("No", 2500)

glm.pred[predTst > .5] <- "Yes"

cTab <- table(glm.pred, test$default  , dnn=c("actual", "predicted") )

addmargins(cTab)

fitted.results <- ifelse(predTst > 0.5,1,0)

misClasificError <- mean(fitted.results !=test$default)

print(paste('Accuracy', 0.9756))
```

The 0.98 accuracy on the test set is quite a good result.

# Performance of the model

## Plot the ROC curve on train and test set

```{r}
# ROC curve on train test and test set
pred_output <- predict(lr.fit,train, type ="response")

predTst <- predict(lr.fit, test, type = "response")

ROCpred_train <- prediction(pred_output, train$default)

ROCpred_test <- prediction(predTst, test$default)

ROCperf_train <- performance(ROCpred_train, "tpr","fpr")

ROCperf_test <- performance(ROCpred_test, "tpr","fpr")

plot(ROCperf_train, col = "red")

plot(ROCperf_test, col = "blue", add =T)
```

## Plot the GAIN curve on train and test set
  
```{r}
# GAIN curve on train test 

GAINperf_train <- performance(ROCpred_train, "tpr","rpp")

GAINperf_test <- performance(ROCpred_test, "tpr","rpp")

plot(GAINperf_train, col = "red")

plot(GAINperf_test, col = "blue", add =T)
```

## Plot the Lift curve on train and test set

```{r}
# Lift curve

LIFTperf_train <- performance(ROCpred_train, "lift","rpp")

LIFTperf_test <- performance(ROCpred_test, "lift","rpp")

plot(LIFTperf_train, col = "red")

plot(LIFTperf_test, col = "blue", add =T)
```
=======
--- 
title: "Logistic Regression"
author: "Ho Duc Ninh"
output:
  html_document:
    code_folding: hide
    fig_caption: yes
    highlight: haddock
    number_sections: yes
    theme: readable
    toc_float: yes
    toc: yes
---

```{r setup, include=FALSE}
setwd("D:/GitHub/analyticsbicc.github.io/Tutorial")
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
library(ggplot2)
library(dplyr)
library(ROCR)
```

# Logistic Regression

## Introduction
 
* Logistic regression or logit regression is a regression model where the dependent variable (DV) is categorical. Binary logistic regression is a type of regression analysis where the dependent variable is a dummy variable (coded 0, 1).

* Logistic regression is used when analyzing whether some event occurred or not, such as voting, participation in a public program, business success or failure, mortality, a hurricane and etc.

## Logistic model

* Same spirit as linear regression

* Desired interpretation: probability to belong to a specific class for the specified inputs. The target value belongs to [0;1].

* Logistic function: 
        $$Logit(p) = Ln(odds) = ln(\frac{p}{1-p}) = \alpha + \sum_{i=1}^n \beta_iX_i$$
    Or:
                          $$f(t) = \frac{1}{( 1+ e^{-t})}$$

* Fitting : Find the estimates that max the likehood of obtaining the training sample. 

# An illustration for logistic regression 

## Objective

Analyse the probability of default using the the expalining variables

## The dataset

The dataset has 4 variables, which are: 
   
* Default: Whether the customer has  actually defaulted or not(binary variable)
* Student: Whether he/she is a student (binary variable)
* Balance: Monthly credit card balance 
* Income: Annual income

## Data exploration   

 Let's see the summary of the dataset 
```{r}
data <- Default
data %>% str
data %>% summary()

data %>% 
  group_by(default) %>% 
  summarise(mean_bal = mean(balance),
            quantile_50_bal = quantile(balance, 0.5),
            mean_inc = mean(income),
            quantile_50_inc=quantile(income,0.5))
```

 The first glance:
 
* There is a notable difference in the mean of balance account of those who defaulted and those who did not.
 
Let's also see the plot of annual incomes and monthly credit card balances of individuals

The individuals who defaulted on their credit card payments are shown in blue, those who did not are shown in red.

```{r}
ggplot(Default, aes(balance, income)) + 
 geom_jitter(aes(color=default)) +
 theme_bw() 
```
 
 From the scatter plot, we can easily see that those have large balance are highly likely to be defaulted. Regarding to income aspect, the difference between groups is not clear.
 
 We will examine the differences in terms of balance and income of the two groups of individuals. 

 With respect to monthly credit card balance: 
```{r}
ggplot(Default, aes(default,balance)) + 
  geom_boxplot(aes(fill = default)) +
  ggtitle("Boxplots of balance as a function of default status") +
  theme_bw() 
```
 
 The plot shows that, there is a significant difference in the monthly balance of those who defaulted and did not default
 
```{r}
ggplot(Default, aes(default,income)) + 
  geom_boxplot(aes(fill = default)) +
  ggtitle("Boxplots of income as a function of default status") +
  theme_bw() 

aov(income ~ default , data = data) %>% TukeyHSD
```

 There is a slight difference between income of those people who defaulted and did not default.

## Logistic model

### Get the train and test set

 We will build model on train test and test the fitted model on test set. 
 
```{r}
bound <- floor((nrow(data)/4)*3)         # define % of training and test set
df <- data[sample(nrow(data)), ]         # sample rows 
train <- data[1:bound, ]              # get training set
test <- data[(bound+1):nrow(df), ]    # get test set
```
  We set the train and test set which account for 75 and 25 percent of total sample respectively.  

### Logistic regression on training set 

 Using logistic regression to predict default = Yes using balance, income and student status. 

```{r}
lr.fit <- glm(default ~ balance +
                        income +
                        student,
            data = train,
            family = binomial())
summary(lr.fit)

```

Interpretation of estimated coefficient:

* The variables: balance and student status are highly associated with the probability of default

* The coefficient for dummy variable (student) is negative, indicating that students are less likely to default than non-student (holding other variables constant)

* We see the coefficient estimate for balance (0.0057) indicates that an increase in balance is associated with an increase in the probability of default

* The z-statistic plays the same role as the t-statistic in the linear regression output

* Null Deviance and Residual Deviance should be small. Model is "good" if Deviance is approx Chi^2 with (df_sat - df_model) degrees of freedom.

### Assessing the predictive ability of the model 

In the steps above, In the steps above, we briefly evaluated the fitting of the model, now we would like to see how the model is doing when predicting y on a new set of data. Our decision boundary will be 0.5. If $$P(y =1|X) > 0.5$$ then y=1 otherwise y=0. 
```{r}

predTst <- predict(lr.fit, test, type = "response")

glm.pred <- rep("No", 2500)

glm.pred[predTst > .5] <- "Yes"

cTab <- table(glm.pred, test$default  , dnn=c("actual", "predicted") )

addmargins(cTab)

fitted.results <- ifelse(predTst > 0.5,1,0)

misClasificError <- mean(fitted.results !=test$default)

print(paste('Accuracy', 0.9756))
```

The 0.98 accuracy on the test set is quite a good result.

# Performance of the model

## Plot the ROC curve on train and test set

```{r}
# ROC curve on train test and test set
pred_output <- predict(lr.fit,train, type ="response")

predTst <- predict(lr.fit, test, type = "response")

ROCpred_train <- prediction(pred_output, train$default)

ROCpred_test <- prediction(predTst, test$default)

ROCperf_train <- performance(ROCpred_train, "tpr","fpr")

ROCperf_test <- performance(ROCpred_test, "tpr","fpr")

plot(ROCperf_train, col = "red")

plot(ROCperf_test, col = "blue", add =T)
```

## Plot the GAIN curve on train and test set
  
```{r}
# GAIN curve on train test 

GAINperf_train <- performance(ROCpred_train, "tpr","rpp")

GAINperf_test <- performance(ROCpred_test, "tpr","rpp")

plot(GAINperf_train, col = "red")

plot(GAINperf_test, col = "blue", add =T)
```

## Plot the Lift curve on train and test set

```{r}
# Lift curve

LIFTperf_train <- performance(ROCpred_train, "lift","rpp")

LIFTperf_test <- performance(ROCpred_test, "lift","rpp")

plot(LIFTperf_train, col = "red")

plot(LIFTperf_test, col = "blue", add =T)
```
>>>>>>> origin/master
